{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c985f2cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.9.1+cpu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.version.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d76b8867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using Tensors\n",
    "x= [45,89,25,64,92]\n",
    "torch.is_tensor(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3485c6be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.is_storage(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "635cccf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=torch.randn(23,67,34,64,28)\n",
    "torch.is_tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86bace31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.is_storage(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "301fbf7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93890048"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.numel(y)#the total number of elements in the input tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c6ecd2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9f566a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.numel(torch.zeros(4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc4063ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(3,4)  #the eye function creates a diagonal matrix, of which the diagonal elements have ones, and off diagonal elements have\n",
    "#zeros. The eye function can be manipulated by providing the shape option"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e29ce8e",
   "metadata": {},
   "source": [
    "Although PyTorch provides a\n",
    "large collection of libraries and modules for computation, three modules\n",
    "are very prominent.\n",
    "• Autograd. This module provides functionality for\n",
    "automatic differentiation of tensors. A recorder class in\n",
    "the program remembers the operations and retrieves\n",
    "those operations with a trigger called backward to\n",
    "compute the gradients. This is immensely helpful in the\n",
    "implementation of neural network models.\n",
    "• Optim. This module provides optimization techniques\n",
    "that can be used to minimize the error function for a\n",
    "specific model. Currently, PyTorch supports various\n",
    "advanced optimization methods, which includes\n",
    "Adam, stochastic gradient descent (SGD), and more.\n",
    "NN. NN stands for neural network model.\n",
    "Manually defining the functions, layers, and further\n",
    "computations using complete tensor operations is very\n",
    "difficult to remember and execute. We need functions\n",
    "that automate the layers, activation functions, loss\n",
    "functions, and optimization functions and provides a\n",
    "layer defined by the user so that manual intervention\n",
    "can be reduced. The NN module has a set of builtin functions that automates the manual process of\n",
    "running a tensor operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5019230e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([45, 89, 25, 64, 92])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x1 = np.array(x)\n",
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28f8e781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([45, 89, 25, 64, 92], dtype=torch.int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad559885",
   "metadata": {},
   "source": [
    "Linear space and points between the linear space can be created using\n",
    "tensor operations. Let’s use an example of creating 25 points in a linear\n",
    "space starting from value 2 and ending with 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e85bf74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.0000,  2.3333,  2.6667,  3.0000,  3.3333,  3.6667,  4.0000,  4.3333,\n",
       "         4.6667,  5.0000,  5.3333,  5.6667,  6.0000,  6.3333,  6.6667,  7.0000,\n",
       "         7.3333,  7.6667,  8.0000,  8.3333,  8.6667,  9.0000,  9.3333,  9.6667,\n",
       "        10.0000])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linspace(2, 10, steps=25) #linear spacing\n",
    "#torch.linspace(3, 10, steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af91f6a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000e-10, 2.6827e-09, 7.1969e-08, 1.9307e-06, 5.1795e-05, 1.3895e-03,\n",
       "        3.7276e-02, 1.0000e+00, 2.6827e+01, 7.1969e+02, 1.9307e+04, 5.1795e+05,\n",
       "        1.3895e+07, 3.7276e+08, 1.0000e+10])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Like linear spacing, logarithmic spacing can be created.\n",
    "torch.logspace(start=-10, end=10,steps=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c8a22a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2285, 0.0642, 0.6654, 0.8246, 0.2579, 0.0115, 0.5754, 0.7466, 0.3520,\n",
       "        0.0947])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#random numbers from a uniform distribution between the values 0 and 1\n",
    "torch.rand(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79c7c91",
   "metadata": {},
   "source": [
    "The following script shows how the random number from two values,\n",
    "0 and 1, are selected. The result tensor can be reshaped to create a (4,5)\n",
    "matrix. The random numbers from a normal distribution with arithmetic\n",
    "mean 0 and standard deviation 1 can also be created, as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b6792c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0993, 0.5152, 0.5540, 0.2413, 0.9036],\n",
       "        [0.0995, 0.9740, 0.1236, 0.6967, 0.1955],\n",
       "        [0.6223, 0.7113, 0.4478, 0.2681, 0.4564],\n",
       "        [0.2592, 0.2132, 0.9900, 0.0598, 0.4361]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(4,5)#random values between 0 and 1 and filled with a matrix of size rows 4 and columns 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6c8c388b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.3228,  1.1538,  0.3841, -1.7216, -0.9077, -2.4868, -0.8622, -0.1351,\n",
       "        -2.8012,  0.0199])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#random numbers from a normal distribution,\n",
    "#with mean=0 and standard deviation = 1\n",
    "torch.randn(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f1d69243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1646, -0.2210,  1.0523,  0.5416,  0.8627],\n",
       "        [ 0.9016, -0.0691, -1.1163, -0.1675,  0.1547],\n",
       "        [-1.1098,  1.0145, -0.4092,  1.3756,  0.1972],\n",
       "        [ 0.5134,  1.0119, -1.0315, -0.8074,  1.2096]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ad25c675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 0, 5, 1, 2, 6, 7, 9, 4, 8])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#selecting values from a range ,this is called random permutation\n",
    "torch.randperm(10)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497c9c1b",
   "metadata": {},
   "source": [
    "When using the arrange function, you must\n",
    "define the step size, which places all the values in an equal distance space.\n",
    "By default, the step size is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f697d821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(10,40,2) #step size 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "27ace448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,\n",
       "        28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(10,40) #step size 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3f845542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a 2dtensor filled with values as 0\n",
    "torch.zeros(4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2946de60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a 1dtensor filled with values as 0\n",
    "torch.zeros(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e158980a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#indexing and performing operation on the tensors\n",
    "x = torch.randn(4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "170f800e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.5857, -1.6895, -0.9806,  0.1532,  0.1346],\n",
       "        [ 1.9240,  0.6930,  2.1854,  0.8121, -0.4223],\n",
       "        [-1.0471,  0.2860, -0.9779, -0.1609,  0.4070],\n",
       "        [-0.5372, -0.9011, -0.1162,  0.5809, -1.3750]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cda6de58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.5857, -1.6895, -0.9806,  0.1532,  0.1346],\n",
       "        [ 1.9240,  0.6930,  2.1854,  0.8121, -0.4223],\n",
       "        [-1.0471,  0.2860, -0.9779, -0.1609,  0.4070],\n",
       "        [-0.5372, -0.9011, -0.1162,  0.5809, -1.3750],\n",
       "        [-1.5857, -1.6895, -0.9806,  0.1532,  0.1346],\n",
       "        [ 1.9240,  0.6930,  2.1854,  0.8121, -0.4223],\n",
       "        [-1.0471,  0.2860, -0.9779, -0.1609,  0.4070],\n",
       "        [-0.5372, -0.9011, -0.1162,  0.5809, -1.3750]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#concatenate two tensors\n",
    "torch.cat((x,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dea0a190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.5857, -1.6895, -0.9806,  0.1532,  0.1346, -1.5857, -1.6895, -0.9806,\n",
       "          0.1532,  0.1346, -1.5857, -1.6895, -0.9806,  0.1532,  0.1346],\n",
       "        [ 1.9240,  0.6930,  2.1854,  0.8121, -0.4223,  1.9240,  0.6930,  2.1854,\n",
       "          0.8121, -0.4223,  1.9240,  0.6930,  2.1854,  0.8121, -0.4223],\n",
       "        [-1.0471,  0.2860, -0.9779, -0.1609,  0.4070, -1.0471,  0.2860, -0.9779,\n",
       "         -0.1609,  0.4070, -1.0471,  0.2860, -0.9779, -0.1609,  0.4070],\n",
       "        [-0.5372, -0.9011, -0.1162,  0.5809, -1.3750, -0.5372, -0.9011, -0.1162,\n",
       "          0.5809, -1.3750, -0.5372, -0.9011, -0.1162,  0.5809, -1.3750]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#concatenate n times based on array size, over column\n",
    "torch.cat((x,x,x),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cf4ad9dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.5857, -1.6895, -0.9806,  0.1532,  0.1346],\n",
       "        [ 1.9240,  0.6930,  2.1854,  0.8121, -0.4223],\n",
       "        [-1.0471,  0.2860, -0.9779, -0.1609,  0.4070],\n",
       "        [-0.5372, -0.9011, -0.1162,  0.5809, -1.3750],\n",
       "        [-1.5857, -1.6895, -0.9806,  0.1532,  0.1346],\n",
       "        [ 1.9240,  0.6930,  2.1854,  0.8121, -0.4223],\n",
       "        [-1.0471,  0.2860, -0.9779, -0.1609,  0.4070],\n",
       "        [-0.5372, -0.9011, -0.1162,  0.5809, -1.3750]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#concatenate n times based on array size, over column\n",
    "torch.cat((x,x),0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610add22",
   "metadata": {},
   "source": [
    "A tensor can be split between multiple chunks. Those small chunks\n",
    "can be created along dim rows and dim columns. The following example\n",
    "shows a sample tensor of size (4,4). The chunk is created using the third\n",
    "argument in the function, as 0 or 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0c04bcd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.8270,  0.2627, -0.3464,  2.0845],\n",
      "        [-0.0587, -1.1112,  2.4332,  0.6597],\n",
      "        [-0.4120,  1.7132, -1.2971,  1.3479],\n",
      "        [-1.6110,  0.9675, -1.8007, -1.1301]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.8270,  0.2627, -0.3464,  2.0845],\n",
       "         [-0.0587, -1.1112,  2.4332,  0.6597]]),\n",
       " tensor([[-0.4120,  1.7132, -1.2971,  1.3479],\n",
       "         [-1.6110,  0.9675, -1.8007, -1.1301]]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(4,4)\n",
    "print(a)\n",
    "torch.chunk(a,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eb6c3f7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.8270,  0.2627, -0.3464,  2.0845],\n",
       "         [-0.0587, -1.1112,  2.4332,  0.6597]]),\n",
       " tensor([[-0.4120,  1.7132, -1.2971,  1.3479],\n",
       "         [-1.6110,  0.9675, -1.8007, -1.1301]]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.chunk(a,2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "80ba410e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.8270,  0.2627],\n",
       "         [-0.0587, -1.1112],\n",
       "         [-0.4120,  1.7132],\n",
       "         [-1.6110,  0.9675]]),\n",
       " tensor([[-0.3464,  2.0845],\n",
       "         [ 2.4332,  0.6597],\n",
       "         [-1.2971,  1.3479],\n",
       "         [-1.8007, -1.1301]]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.chunk(a,2,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c38ad14",
   "metadata": {},
   "source": [
    "The gather function collects elements from a tensor and places it in\n",
    "another tensor using an index argument. The index position is determined\n",
    "by the LongTensor function in PyTorch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d7445e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11., 12.],\n",
       "        [23., 24.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor([[11,12],[23,24]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "117dcb57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11., 11.],\n",
       "        [24., 23.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.gather(torch.Tensor([[11,12],[23,24]]),1,\n",
    "             torch.LongTensor([[0,0],[1,0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "db665701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0],\n",
       "        [1, 0]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.LongTensor([[0,0],[1,0]])\n",
    "#the  ID tensor containing the indices to index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5738a276",
   "metadata": {},
   "source": [
    "The LongTensor function or the index select function can be used to\n",
    "fetch relevant values from a tensor. The following sample code shows two\n",
    "options: selection along rows and selection along columns. If the second\n",
    "argument is 0, it is for rows. If it is 1, then it is along the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "83142e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.6277, -2.0711,  0.7167,  0.9953],\n",
      "        [ 0.4511,  0.4283, -1.2487,  1.8526],\n",
      "        [-0.2400, -0.2030, -0.0682, -0.9124],\n",
      "        [ 0.7833,  2.2397, -1.2834, -0.2132]])\n"
     ]
    }
   ],
   "source": [
    "a=torch.randn(4,4)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9371fe80",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = torch.LongTensor([0,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f5ea57e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6277, -2.0711,  0.7167,  0.9953],\n",
       "        [-0.2400, -0.2030, -0.0682, -0.9124]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.index_select(a,0,indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "93ab540b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6277,  0.7167],\n",
       "        [ 0.4511, -1.2487],\n",
       "        [-0.2400, -0.0682],\n",
       "        [ 0.7833, -1.2834]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.index_select(a,1,indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe8c0f2",
   "metadata": {},
   "source": [
    "It is a common practice to check non-missing values in a tensor, the\n",
    "objective is to identify non-zero elements in a large tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "02d8305a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [2]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nonzero(torch.tensor([10,00,23,0,0,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a6767e",
   "metadata": {},
   "source": [
    "Restructuring the input tensors into smaller tensors not only fastens\n",
    "the calculation process, but also helps in distributed computing. The split\n",
    "function splits a long tensor into smaller tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "27d337e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([12, 21]), tensor([34, 32]), tensor([45, 54]), tensor([56, 65]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#splitting the tensor into small chunks\n",
    "torch.split(torch.tensor([12,21,34,32,45,54,56,65]),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "45a31e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([12, 21, 34]), tensor([32, 45, 54]), tensor([56, 65]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#splitting the tensor into small chunks\n",
    "torch.split(torch.tensor([12,21,34,32,45,54,56,65]),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd770034",
   "metadata": {},
   "source": [
    "The transpose function is\n",
    "primarily used to reshape tensors. There are two ways of writing the\n",
    "transpose function: .t and .transpose.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0c0a83cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#how to reshape the tensors along a new dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bc67d19d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.5857, -1.6895, -0.9806,  0.1532,  0.1346],\n",
       "        [ 1.9240,  0.6930,  2.1854,  0.8121, -0.4223],\n",
       "        [-1.0471,  0.2860, -0.9779, -0.1609,  0.4070],\n",
       "        [-0.5372, -0.9011, -0.1162,  0.5809, -1.3750]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0e123938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.5857,  1.9240, -1.0471, -0.5372],\n",
       "        [-1.6895,  0.6930,  0.2860, -0.9011],\n",
       "        [-0.9806,  2.1854, -0.9779, -0.1162],\n",
       "        [ 0.1532,  0.8121, -0.1609,  0.5809],\n",
       "        [ 0.1346, -0.4223,  0.4070, -1.3750]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.t() #transpose is one option to change the shape of the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "63fb3a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.5857,  1.9240, -1.0471, -0.5372],\n",
       "        [-1.6895,  0.6930,  0.2860, -0.9011],\n",
       "        [-0.9806,  2.1854, -0.9779, -0.1162],\n",
       "        [ 0.1532,  0.8121, -0.1609,  0.5809],\n",
       "        [ 0.1346, -0.4223,  0.4070, -1.3750]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.transpose(1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c982f7",
   "metadata": {},
   "source": [
    "The unbind function removes a dimension from a tensor. To remove\n",
    "the dimension row, the 0 value needs to be passed. To remove a column,\n",
    "the 1 value needs to be passed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8628ed94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.5857, -1.6895, -0.9806,  0.1532,  0.1346],\n",
       "        [ 1.9240,  0.6930,  2.1854,  0.8121, -0.4223],\n",
       "        [-1.0471,  0.2860, -0.9779, -0.1609,  0.4070],\n",
       "        [-0.5372, -0.9011, -0.1162,  0.5809, -1.3750]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "62cc0d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-1.5857,  1.9240, -1.0471, -0.5372]),\n",
       " tensor([-1.6895,  0.6930,  0.2860, -0.9011]),\n",
       " tensor([-0.9806,  2.1854, -0.9779, -0.1162]),\n",
       " tensor([ 0.1532,  0.8121, -0.1609,  0.5809]),\n",
       " tensor([ 0.1346, -0.4223,  0.4070, -1.3750]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unbind(x,1) #dim=1 removing a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a978a78a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-1.5857, -1.6895, -0.9806,  0.1532,  0.1346]),\n",
       " tensor([ 1.9240,  0.6930,  2.1854,  0.8121, -0.4223]),\n",
       " tensor([-1.0471,  0.2860, -0.9779, -0.1609,  0.4070]),\n",
       " tensor([-0.5372, -0.9011, -0.1162,  0.5809, -1.3750]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unbind(x) #dim=0 removing a row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7c8cb500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.5857, -1.6895, -0.9806,  0.1532,  0.1346],\n",
       "        [ 1.9240,  0.6930,  2.1854,  0.8121, -0.4223],\n",
       "        [-1.0471,  0.2860, -0.9779, -0.1609,  0.4070],\n",
       "        [-0.5372, -0.9011, -0.1162,  0.5809, -1.3750]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7213ee24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[18.4143, 18.3105, 19.0194, 20.1532, 20.1346],\n",
       "        [21.9240, 20.6930, 22.1854, 20.8121, 19.5777],\n",
       "        [18.9529, 20.2860, 19.0221, 19.8391, 20.4070],\n",
       "        [19.4628, 19.0989, 19.8838, 20.5809, 18.6250]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#addition value to the existing tensor,scalar addition\n",
    "torch.add(x,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "09979a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.1714, -3.3790, -1.9612,  0.3065,  0.2693],\n",
       "        [ 3.8481,  1.3860,  4.3708,  1.6242, -0.8446],\n",
       "        [-2.0941,  0.5721, -1.9557, -0.3219,  0.8139],\n",
       "        [-1.0745, -1.8023, -0.2325,  1.1619, -2.7500]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scalar multiplication\n",
    "torch.mul(x,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0088f496",
   "metadata": {},
   "source": [
    "torch.argmin(input, dim=None, keepdim=False)[SOURCE]\n",
    "Returns the indices of the minimum values of a tensor across a dimension.\n",
    "\n",
    "This is the second value returned by torch.min(). See its documentation for the exact semantics of this method.\n",
    "\n",
    "Parameters:\t\n",
    "input (Tensor) – the input tensor\n",
    "dim (int) – the dimension to reduce. If None, the argmin of the flattened input is returned.\n",
    "keepdim (bool) – whether the output tensors have dim retained or not. Ignored if dim=None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20c4b26d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5031, -0.3597,  0.5115, -0.8496, -0.5085],\n",
       "        [ 1.3130,  0.0022, -0.1272, -0.5685, -1.5096],\n",
       "        [ 1.5656, -0.4109, -0.1015,  0.8786,  0.9383],\n",
       "        [-0.0375, -0.1174,  0.5063, -0.8111,  0.1513]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "d= torch.randn(4,5)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d71798ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 4, 1, 3])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmin(d,dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b3ccec",
   "metadata": {},
   "source": [
    "torch.argmax(input, dim=None, keepdim=False)[SOURCE]\n",
    "Returns the indices of the maximum values of a tensor across a dimension.\n",
    "\n",
    "This is the second value returned by torch.max(). See its documentation for the exact semantics of this method.\n",
    "\n",
    "Parameters:\t\n",
    "input (Tensor) – the input tensor\n",
    "dim (int) – the dimension to reduce. If None, the argmax of the flattened input is returned.\n",
    "keepdim (bool) – whether the output tensors have dim retained or not. Ignored if dim=None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cf998d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 0, 0, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(d,dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02162090",
   "metadata": {},
   "source": [
    "Like NumPy operations, the tensor values must be rounded up by \n",
    "using either the ceiling or the flooring function, which is done using the \n",
    "following syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c254c83a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1117, -0.4966,  0.1631, -0.8817,  0.0539],\n",
       "        [ 0.6684, -0.0597, -0.4675, -0.2153, -0.7141],\n",
       "        [-1.0831, -0.5547,  0.9717, -0.5150,  1.4255],\n",
       "        [ 0.7987, -1.4949,  1.4778, -0.1696, -0.9919],\n",
       "        [-1.4569,  0.2563, -0.4030,  0.4195,  0.9380]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1234)\n",
    "torch.randn(5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e96df72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0., -0.,  1., -0.,  1.],\n",
       "        [ 1., -0., -0., -0., -0.],\n",
       "        [-1., -0.,  1., -0.,  2.],\n",
       "        [ 1., -1.,  2., -0., -0.],\n",
       "        [-1.,  1., -0.,  1.,  1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1234)\n",
    "torch.ceil(torch.randn(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "757df162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1., -1.,  0., -1.,  0.],\n",
       "        [ 0., -1., -1., -1., -1.],\n",
       "        [-2., -1.,  0., -1.,  1.],\n",
       "        [ 0., -2.,  1., -1., -1.],\n",
       "        [-2.,  0., -1.,  0.,  0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1234)\n",
    "torch.floor(torch.randn(5,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a54d260",
   "metadata": {},
   "source": [
    "Limiting the values of any tensor within a certain range can be done \n",
    "using the minimum and maximum argument and using the clamp \n",
    "function. The same function can apply minimum and maximum in \n",
    "parallel or any one of them to any tensor, be it 1D or 2D; 1D is the far \n",
    "simpler version. The following example shows the implementation in \n",
    "a 2D scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56d62b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3000, 0.3000, 0.3000, 0.3000, 0.3000],\n",
       "        [0.3000, 0.3000, 0.3000, 0.3000, 0.3000],\n",
       "        [0.3000, 0.3000, 0.3000, 0.3000, 0.4000],\n",
       "        [0.3000, 0.3000, 0.4000, 0.3000, 0.3000],\n",
       "        [0.3000, 0.3000, 0.3000, 0.3000, 0.3000]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trucate the values in a range say 0,1\n",
    "torch.manual_seed(1234)\n",
    "torch.clamp(torch.floor(torch.randn(5,5)), min=0.3,max=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75b314a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3000, -0.3000,  0.0000, -0.3000,  0.0000],\n",
       "        [ 0.0000, -0.3000, -0.3000, -0.3000, -0.3000],\n",
       "        [-0.3000, -0.3000,  0.0000, -0.3000,  1.0000],\n",
       "        [ 0.0000, -0.3000,  1.0000, -0.3000, -0.3000],\n",
       "        [-0.3000,  0.0000, -0.3000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trucate with only lower limit\n",
    "torch.manual_seed(1234)\n",
    "torch.clamp(torch.floor(torch.randn(5,5)), min=-0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eba5328d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0000, -1.0000,  0.0000, -1.0000,  0.0000],\n",
       "        [ 0.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "        [-2.0000, -1.0000,  0.0000, -1.0000,  0.3000],\n",
       "        [ 0.0000, -2.0000,  0.3000, -1.0000, -1.0000],\n",
       "        [-2.0000,  0.0000, -1.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trucate with only upper limit\n",
    "torch.manual_seed(1234)\n",
    "torch.clamp(torch.floor(torch.randn(5,5)), max=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fbbf55fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.2550,  0.2626],\n",
       "        [-0.0773,  0.2841]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.randn(2,2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5bce56b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.5079, 1.3003],\n",
       "        [0.9256, 1.3286]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compute the exponential of a tensor\n",
    "torch.exp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb2f48c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.5079, 1.3003],\n",
       "        [0.9256, 1.3286]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.exp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31e4a8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#how to get fractional part of each tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "91bd0bbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11.2550, 10.2626],\n",
       "        [ 9.9227, 10.2841]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(x,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34d7d038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2550, 0.2626],\n",
       "        [0.9227, 0.2841]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.frac(torch.add(x,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aca5644",
   "metadata": {},
   "source": [
    "#The following syntax explains the logarithmic values in a tensor. The \n",
    "values with a negative sign are converted to nan. The power function \n",
    "computes the exponential of any value in a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa3c2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute the log of the values in a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31157453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.2550,  0.2626],\n",
       "        [-0.0773,  0.2841]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3fbcabb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2271, -1.3370],\n",
       "        [    nan, -1.2583]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cb94fc3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.5751, 0.0690],\n",
       "        [0.0060, 0.0807]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to rectify the negative values do a power transformation\n",
    "torch.pow(x,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c684b0b8",
   "metadata": {},
   "source": [
    "To compute the transformation functions (i.e., sigmoid, hyperbolic \n",
    "tangent, radial basis function, and so forth, which are the most commonly \n",
    "used transfer functions in deep learning), you must construct the tensors. \n",
    "The following sample script shows how to create a sigmoid function and \n",
    "apply it on a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd94d1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#how to compute the sigmid of the input tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd2adf71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.2550,  0.2626],\n",
       "        [-0.0773,  0.2841]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "547ce858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7782, 0.5653],\n",
       "        [0.4807, 0.5706]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7d313f9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.2550,  0.2626],\n",
       "        [-0.0773,  0.2841]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding the squareroot of the values\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cd2dba89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.1203, 0.5125],\n",
       "        [   nan, 0.5331]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sqrt(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd869002",
   "metadata": {},
   "source": [
    "In probability and statistics, a random variable is also known as a \n",
    "stochastic variable, whose outcome is dependent on a purely stochastic \n",
    "phenomenon, or random phenomenon. There are different types of \n",
    "probability distributions, including normal distribution, binomial \n",
    "distribution, multinomial distribution, and Bernoulli distribution. Each \n",
    "statistical distribution has its own properties.\n",
    "The torch.distributions module contains probability distributions \n",
    "and sampling functions. Each distribution type has its own importance \n",
    "in a computational graph. The distributions module contains binomial, \n",
    "Bernoulli, beta, categorical, exponential, normal, and Poisson \n",
    "distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90da73b4",
   "metadata": {},
   "source": [
    "Problem\n",
    "Weight initialization is an important task in training a neural network and \n",
    "any kind of deep learning model, such as a convolutional neural network \n",
    "(CNN), a deep neural network (DNN), and a recurrent neural network \n",
    "(RNN). The question always remains on how to initialize the weights.\n",
    "Solution\n",
    "Weight initialization can be done by using various methods, including \n",
    "random weight initialization. Weight initialization based on a distribution \n",
    "is done using uniform distribution, Bernoulli distribution, multinomial \n",
    "distribution, and normal distribution. How to do it using PyTorch is \n",
    "explained next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebd898b",
   "metadata": {},
   "source": [
    "How It Works\n",
    "To execute a neural network, a set of initial weights needs to be passed to \n",
    "the backpropagation layer to compute the loss function (and hence, the \n",
    "accuracy can be calculated). The selection of a method depends on the \n",
    "data type, the task, and the optimization required for the model. Here we \n",
    "are going to look at all types of approaches to initialize weights.\n",
    "If the use case requires reproducing the same set of results to maintain \n",
    "consistency, then a manual seed needs to be set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f4c3a2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "29495b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#how to perform random sampling of the tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "01ad112f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2207ce458b0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bd649d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1117, -0.4966,  0.1631, -0.8817],\n",
       "        [ 0.0539,  0.6684, -0.0597, -0.4675],\n",
       "        [-0.2153,  0.8840, -0.7584, -0.3689],\n",
       "        [-0.3424, -1.4020,  0.3206, -1.0219]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1234)\n",
    "torch.randn(4,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049494a3",
   "metadata": {},
   "source": [
    "The seed value can be customized. The random number is generated \n",
    "purely by chance. Random numbers can also be generated from a \n",
    "statistical distribution. The probability density function of the continuous \n",
    "uniform distribution is defined by the following formula.\n",
    "f(x)= 1/(b-a)  for a<= x <=b,\n",
    "f(x)=0   for a< x >b,\n",
    "The function of x has two points, a and b, in which a is the starting \n",
    "point and b is the end. In a continuous uniform distribution, each number \n",
    "has an equal chance of being selected. In the following example, the start \n",
    "is 0 and the end is 1; between those two digits, all 16 elements are selected \n",
    "randoml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "49d4f993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2837, 0.6567, 0.2388, 0.7313],\n",
       "        [0.6012, 0.3043, 0.2548, 0.6294],\n",
       "        [0.9665, 0.7399, 0.4517, 0.4757],\n",
       "        [0.7842, 0.1525, 0.6662, 0.3343]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(4,4).uniform_(0,1) #random number from uniform distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addd4810",
   "metadata": {},
   "source": [
    "In statistics, the Bernoulli distribution is considered as the discrete \n",
    "probability distribution, which has two possible outcomes. If the event \n",
    "happens, then the value is 1, and if the event does not happen, then the \n",
    "value is 0.\n",
    "For discrete probability distribution, we calculate probability mass \n",
    "function instead of probability density function. The probability mass \n",
    "function looks like the following formula.\n",
    "q=(1-p)  fork=0\n",
    "     p   fork=1\n",
    "From the Bernoulli distribution, we create sample tensors by \n",
    "considering the uniform distribution of size 4 and 4 in a matrix format, \n",
    "as follow\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2103cf2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [1., 0., 1., 0.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.bernoulli(torch.Tensor(4,4).uniform_(0,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c745ef6b",
   "metadata": {},
   "source": [
    "The generation of sample random values from a multinomial \n",
    "distribution is defined by the following script. In a multinomial \n",
    "distribution, we can choose with a replacement or without a replacement. \n",
    "By default, the multinomial function picks up without a replacement and \n",
    "returns the result as an index position for the tensors. If we need to run it \n",
    "with a replacement, then we need to specify that while sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "be252fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10., 10., 13., 10., 34., 45., 65., 67., 87., 89., 87., 34.])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor([10,10,13,10,34,45,65,67,87,89,87,34])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "980b479e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8, 11,  5,  6])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.multinomial(torch.Tensor([10,10,13,10,34,45,65,67,87,89,87,34]), num_samples=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2d2e0a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 10,  9, 11])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sampling from multinomial distribution with a replacement returns \n",
    "#the tensors’ index values\n",
    "torch.multinomial(torch.Tensor([10,10,13,10,34,45,65,67,87,89,87,34]), num_samples=4,replacement=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804eaa98",
   "metadata": {},
   "source": [
    "The weight initialization from the normal distribution is a method \n",
    "that is used in fitting a neural network, fitting a deep neural network, and \n",
    "CNN and RNN. Let’s have a look at the process of creating a set of random \n",
    "weights generated from a normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5a31ec9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.6486, 3.5888, 3.8649, 4.8705, 5.5382, 5.9608, 7.2219, 7.9747, 9.1181,\n",
       "        9.8997])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.normal(mean=torch.arange(1.,11.),\n",
    "                            std=torch.arange(1,0,-0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "462ceb0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.2873,  0.6076,  2.9737, -1.7891, -1.9382])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.normal(mean=0.5,\n",
    "                            std=torch.arange(1.,6.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "90fd478d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5389])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.normal(mean=0.5,\n",
    "                            std=torch.arange(0.2,0.6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b20c0e9",
   "metadata": {},
   "source": [
    "#What is a variable in PyTorch and how is it defined? What is a random \n",
    "#variable in PyTorch\n",
    "Solution\n",
    "In PyTorch, the algorithms are represented as a computational graph. \n",
    "A variable is considered as a representation around the tensor object, \n",
    "corresponding gradients, and a reference to the function from where it was \n",
    "created. For simplicity, gradients are considered as slope of the function. \n",
    "The slope of the function can be computed by the derivative of the \n",
    "function with respect to the parameters that are present in the function. \n",
    "For example, in linear regression (Y = W*X + alpha), \n",
    "Basically, a PyTorch variable is a node in a computational graph, which \n",
    "stores data and gradients. When training a neural network model, after \n",
    "each iteration, we need to compute the gradient of the loss function with \n",
    "respect to the parameters of the model, such as weights and biases. After \n",
    "that, we usually update the weights using the gradient descent algorithm. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfc807b",
   "metadata": {},
   "source": [
    "How It Works\n",
    "An example of how a variable is used to create a computational graph is \n",
    "displayed in the following script. There are three variable objects around \n",
    "tensors— x1, x2, and x3—with random points generated from a = 12 and \n",
    "b = 23. The graph computation involves only multiplication and addition, \n",
    "and the final result with the gradient is shown.\n",
    "The partial derivative of the loss function with respect to the weights \n",
    "and biases in a neural network model is achieved in PyTorch using the \n",
    "Autograd module. Variables are specifically designed to hold the changed \n",
    "values while running a backpropagation in a neural network model when \n",
    "the parameters of the model change. The variable type is just a wrapper \n",
    "around the tensor. It has three properties: data, grad, and function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bd23f057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]], requires_grad=True)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.autograd  import Variable\n",
    "Variable(torch.ones(2,2),requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1fb2780a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = 12,23\n",
    "x1 = Variable(torch.randn(a,b),\n",
    "                        requires_grad=True)\n",
    "x2 = Variable(torch.randn(a,b),\n",
    "                        requires_grad=True)\n",
    "x3 = Variable(torch.randn(a,b),\n",
    "                        requires_grad=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6bce008e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3299.6853, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "c = x1 * x2\n",
    "d = a+x3\n",
    "e = torch.sum(d)\n",
    "\n",
    "e.backward()\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697d4bf8",
   "metadata": {},
   "source": [
    "How do we compute basic statistics, such as mean, median, mode, and so \n",
    "forth, from a Torch tensor\n",
    "\n",
    "\n",
    "Solution\n",
    "\n",
    "Computation of basic statistics using PyTorch enables the user to apply \n",
    "probability distributions and statistical tests to make inferences from data. \n",
    "Though the Torch functionality is like that of Numpy, Torch functions have \n",
    "GPU acceleration. Let’s have a look at the functions to create basic statistic\n",
    "\n",
    "How It Works\n",
    "\n",
    "The mean computation is simple to write for a 1D tensor; however, for a 2D \n",
    "tensor, an extra argument needs to be passed as a mean, median, or mode \n",
    "computation, across which the dimension needs to be specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e5e2cdec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(45.9167)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#computing the descriptive statistics: mean\n",
    "torch.mean(torch.tensor([10.,10.,13.,10.,34.,45.,65.,67.,87.,89.,87.,34.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "133fe6cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0981, -0.1275,  0.1092, -0.2081, -0.6718],\n",
       "        [-0.7763,  1.1963, -0.4281,  0.7897, -1.5123],\n",
       "        [ 0.4537, -0.5508,  0.5083, -0.0619, -0.7811],\n",
       "        [ 1.3835, -0.2480,  0.2184,  0.7165, -1.0857]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mean across rows and across columns\n",
    "d =torch.randn(4,5)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f5e8d3bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2898,  0.0675,  0.1020,  0.3091, -1.0127])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(d,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ab5418f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1600, -0.1461, -0.0864,  0.1970])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(d,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6da7ec86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Median, mode, and standard deviation computation can be written in \n",
    "#he same way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9c479178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.median(\n",
       "values=tensor([ 0.0981, -0.2480,  0.1092, -0.0619, -1.0857]),\n",
       "indices=tensor([0, 3, 0, 2, 3]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compute median\n",
    "torch.median(d,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cb038272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.median(\n",
       "values=tensor([-0.1275, -0.4281, -0.0619,  0.2184]),\n",
       "indices=tensor([1, 2, 3, 2]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.median(d,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c49e68d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.mode(\n",
       "values=tensor([-0.6718, -1.5123, -0.7811, -1.0857]),\n",
       "indices=tensor([4, 4, 4, 4]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compute the mode\n",
    "torch.mode(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5be777be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.mode(\n",
       "values=tensor([-0.7763, -0.5508, -0.4281, -0.2081, -1.5123]),\n",
       "indices=tensor([1, 2, 1, 0, 1]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mode(d,dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7eb440cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.mode(\n",
       "values=tensor([-0.6718, -1.5123, -0.7811, -1.0857]),\n",
       "indices=tensor([4, 4, 4, 4]))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mode(d,dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7eba1d4",
   "metadata": {},
   "source": [
    "Standard deviation shows the deviation from the measures of central \n",
    "tendency, which indicates the consistency of the data/variable. It shows \n",
    "whether there is enough fluctuation in data or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "089587fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7508)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compute the standard deviation\n",
    "torch.std(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c7947cdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8938, 0.7733, 0.3914, 0.5170, 0.3763])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.std(d,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1d9036d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3180, 1.1203, 0.5797, 0.9383])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.std(d,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "17b624c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5636)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compute variance\n",
    "torch.var(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "675334e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7988, 0.5980, 0.1532, 0.2673, 0.1416])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.var(d,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7a963aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1011, 1.2552, 0.3360, 0.8804])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.var(d,dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf46490",
   "metadata": {},
   "source": [
    "Gradient Computation\n",
    "Problem\n",
    "How do we compute basic gradients from the sample tensors using \n",
    "PyTorch?\n",
    "Solution\n",
    "We are going to consider a sample datase0074, where two variables (x and y) \n",
    "are present. With the initial weight given, can we computationally get the \n",
    "gradients after each iteration? Let’s take a look at the example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba6e640",
   "metadata": {},
   "source": [
    "How It Works\n",
    "x_data and y_data both are lists. To compute the gradient of the two data \n",
    "lists requires computation of a loss function, a forward pass, and running \n",
    "the stuff in a loop.\n",
    "The forward function computes the matrix multiplication of the weight \n",
    "tensor with the input tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5a70d065",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x):\n",
    "        return x * w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4bec7ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict (before training) 4 tensor(4.)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "x_data = [11.0,22.0,33.0]\n",
    "y_data = [21.0,14.0,64.0]\n",
    "\n",
    "w = Variable(torch.Tensor([1.0]),  requires_grad=True) #Any random value\n",
    "\n",
    "#Before training\n",
    "print(\"predict (before training)\",4,forward(4).data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "91fd43a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using forward pass\n",
    "def forward(x):\n",
    "        return x * w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "39f3a461",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the Loss function\n",
    "def  loss(x,y):\n",
    "      y_pred = forward(x)\n",
    "      return (y_pred - y) * (y_pred - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d149f062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tgrad:   11.0 21.0 tensor(-220.)\n",
      "\tgrad:   22.0 14.0 tensor(2481.6001)\n",
      "\tgrad:   33.0 64.0 tensor(-51303.6484)\n",
      "progress: 0 tensor(604238.8125)\n",
      "\tgrad:   11.0 21.0 tensor(118461.7578)\n",
      "\tgrad:   22.0 14.0 tensor(-671630.6875)\n",
      "\tgrad:   33.0 64.0 tensor(13114108.)\n",
      "progress: 1 tensor(3.9481e+10)\n",
      "\tgrad:   11.0 21.0 tensor(-30279010.)\n",
      "\tgrad:   22.0 14.0 tensor(1.7199e+08)\n",
      "\tgrad:   33.0 64.0 tensor(-3.3589e+09)\n",
      "progress: 2 tensor(2.5900e+15)\n",
      "\tgrad:   11.0 21.0 tensor(7.7553e+09)\n",
      "\tgrad:   22.0 14.0 tensor(-4.4050e+10)\n",
      "\tgrad:   33.0 64.0 tensor(8.6030e+11)\n",
      "progress: 3 tensor(1.6991e+20)\n",
      "\tgrad:   11.0 21.0 tensor(-1.9863e+12)\n",
      "\tgrad:   22.0 14.0 tensor(1.1282e+13)\n",
      "\tgrad:   33.0 64.0 tensor(-2.2034e+14)\n",
      "progress: 4 tensor(1.1146e+25)\n",
      "\tgrad:   11.0 21.0 tensor(5.0875e+14)\n",
      "\tgrad:   22.0 14.0 tensor(-2.8897e+15)\n",
      "\tgrad:   33.0 64.0 tensor(5.6436e+16)\n",
      "progress: 5 tensor(7.3118e+29)\n",
      "\tgrad:   11.0 21.0 tensor(-1.3030e+17)\n",
      "\tgrad:   22.0 14.0 tensor(7.4013e+17)\n",
      "\tgrad:   33.0 64.0 tensor(-1.4455e+19)\n",
      "progress: 6 tensor(4.7966e+34)\n",
      "\tgrad:   11.0 21.0 tensor(3.3374e+19)\n",
      "\tgrad:   22.0 14.0 tensor(-1.8957e+20)\n",
      "\tgrad:   33.0 64.0 tensor(3.7022e+21)\n",
      "progress: 7 tensor(inf)\n",
      "\tgrad:   11.0 21.0 tensor(-8.5480e+21)\n",
      "\tgrad:   22.0 14.0 tensor(4.8553e+22)\n",
      "\tgrad:   33.0 64.0 tensor(-9.4824e+23)\n",
      "progress: 8 tensor(inf)\n",
      "\tgrad:   11.0 21.0 tensor(2.1894e+24)\n",
      "\tgrad:   22.0 14.0 tensor(-1.2436e+25)\n",
      "\tgrad:   33.0 64.0 tensor(2.4287e+26)\n",
      "progress: 9 tensor(inf)\n"
     ]
    }
   ],
   "source": [
    "#Run the Training Loop\n",
    "for epoch in range(10):\n",
    "       for x_val, y_val in zip(x_data, y_data):\n",
    "        l = loss(x_val, y_val)\n",
    "        l.backward()\n",
    "        print(\"\\tgrad:  \",x_val, y_val,w.grad.data[0])\n",
    "        w.data = w.data - 0.01 * w.grad.data\n",
    "\n",
    "          #Manually set the gradients to zero after updating weights\n",
    "        w.grad.data.zero_()\n",
    "       print(\"progress:\",epoch,l.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "031b1342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict ( after training) 4 tensor(-9.2687e+24)\n"
     ]
    }
   ],
   "source": [
    "#After training\n",
    "print(\"predict ( after training)\",4, forward(4).data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e001ec",
   "metadata": {},
   "source": [
    "The following program shows how to compute the gradients from a \n",
    "loss function using the variable method on the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f654fc25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient of w1 w.r.t.  to Loss:  -455.0\n",
      "Gradient of w2 w.r.t.  to Loss:  -365.0\n",
      "Gradient of w3 w.r.t.  to Loss:  -60.0\n",
      "Gradient of w4 w.r.t.  to Loss:  -265.0\n"
     ]
    }
   ],
   "source": [
    "from torch import FloatTensor\n",
    "from torch.autograd import Variable\n",
    "\n",
    "a = Variable(FloatTensor([5]))\n",
    "\n",
    "weights = [Variable(FloatTensor([i]), requires_grad=True) for i in (12,53,91,73)]\n",
    "\n",
    "w1,w2,w3,w4 = weights\n",
    "\n",
    "b = w1 * a\n",
    "c = w2 * a\n",
    "d = w3 * b + w4 * c\n",
    "Loss = (10 - d)\n",
    "\n",
    "Loss.backward()\n",
    "\n",
    "for index,weight in enumerate(weights,start=1):\n",
    "       gradient, *_= weight.grad.data\n",
    "       print(f\"Gradient of w{index} w.r.t.  to Loss:  {gradient}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c82c95b",
   "metadata": {},
   "source": [
    "Problem\n",
    "How do we compute or perform operations based on variables such as \n",
    "matrix multiplication?\n",
    "Solution\n",
    "Tensors are wrapped within the variable, which has three properties: grad, \n",
    "volatile, and gradient.\n",
    "How It Works\n",
    "Let’s create a variable and extract the properties of the variable. This is \n",
    "required to weight update process requires gradient computation. By using \n",
    "the mm module, we can perform matrix multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e81d3f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2f01036a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4])\n"
     ]
    }
   ],
   "source": [
    "x = Variable(torch.Tensor(4,4).uniform_(-4,5))\n",
    "y = Variable(torch.Tensor(4,4).uniform_(-3,2))\n",
    "#matrix multiplication\n",
    "z = torch.mm(x,y)\n",
    "print(z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7338f458",
   "metadata": {},
   "source": [
    "The following program shows the properties of the variable, which is a \n",
    "wrapper around the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "051404d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4.5875, -2.3846,  2.2561,  2.6735],\n",
      "        [ 0.6668, -3.1370, -0.3582, -0.9842],\n",
      "        [ 4.9814,  3.4517,  0.5688,  2.6663],\n",
      "        [-3.9159,  2.8737,  2.3478,  4.9391]])\n"
     ]
    }
   ],
   "source": [
    "z = Variable(torch.Tensor(4,4).uniform_(-5,5))\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "047155d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requires Gradient : False \n",
      "Volatile : False \n",
      "Gradient : None \n",
      "tensor([[ 4.5875, -2.3846,  2.2561,  2.6735],\n",
      "        [ 0.6668, -3.1370, -0.3582, -0.9842],\n",
      "        [ 4.9814,  3.4517,  0.5688,  2.6663],\n",
      "        [-3.9159,  2.8737,  2.3478,  4.9391]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ramesh\\AppData\\Local\\Temp/ipykernel_760/1823587207.py:2: UserWarning: volatile was removed (Variable.volatile is always False)\n",
      "  print('Volatile : %s ' %(z.volatile))\n"
     ]
    }
   ],
   "source": [
    "print('Requires Gradient : %s ' %(z.requires_grad))\n",
    "print('Volatile : %s ' %(z.volatile))\n",
    "print('Gradient : %s ' %(z.grad))\n",
    "print(z.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0643e4b8",
   "metadata": {},
   "source": [
    "Problem\n",
    "How do we compute or perform operations based on variables such \n",
    "as matrix-vector computation, and matrix-matrix and vector-vector \n",
    "calculation?\n",
    "Solution\n",
    "One of the necessary conditions for the success of matrix-based operations \n",
    "is that the length of the tensor needs to match or be compatible for the \n",
    "execution of algebraic expressions\n",
    "How It Works\n",
    "The tensor definition of a scalar is just one number. A 1D tensor is a \n",
    "vector, and a 2D tensor is a matrix. When it extends to an n dimensional \n",
    "level, it can be generalized to only tensors. When performing algebraic \n",
    "computations in PyTorch, the dimension of a matrix and a vector or scalar \n",
    "should be compatible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "730eee73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensor operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e478c91e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3580, 0.1682, 0.9159, 0.9878],\n",
       "        [0.5393, 0.6097, 0.9861, 0.0763],\n",
       "        [0.3469, 0.1317, 0.7387, 0.8339],\n",
       "        [0.0693, 0.4194, 0.0466, 0.8690]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat1 = torch.FloatTensor(4,4).uniform_(0,1)\n",
    "mat1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "12a46e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8990, 0.6630, 0.4962, 0.4947],\n",
       "        [0.8344, 0.6721, 0.1182, 0.5997],\n",
       "        [0.8990, 0.8252, 0.1466, 0.1093],\n",
       "        [0.8135, 0.9047, 0.2486, 0.1873],\n",
       "        [0.6159, 0.2471, 0.7582, 0.6879]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat2 = torch.FloatTensor(5,4).uniform_(0,1)\n",
    "mat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "597f50fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8949, 0.3995, 0.3528, 0.1089])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec1 = torch.FloatTensor(4).uniform_(0,1)\n",
    "vec1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6b658247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10.8580, 10.6682, 11.4159, 11.4878],\n",
       "        [11.0393, 11.1097, 11.4861, 10.5763],\n",
       "        [10.8469, 10.6317, 11.2387, 11.3339],\n",
       "        [10.5693, 10.9194, 10.5466, 11.3690]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat1 + 10.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b6caa545",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scalar subtraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2a09e712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6990,  0.4630,  0.2962,  0.2947],\n",
       "        [ 0.6344,  0.4721, -0.0818,  0.3997],\n",
       "        [ 0.6990,  0.6252, -0.0534, -0.0907],\n",
       "        [ 0.6135,  0.7047,  0.0486, -0.0127],\n",
       "        [ 0.4159,  0.0471,  0.5582,  0.4879]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat2 - 0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "99c69954",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vector and matrix addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a86d48dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.2530, 0.5676, 1.2687, 1.0967],\n",
       "        [1.4342, 1.0092, 1.3389, 0.1852],\n",
       "        [1.2418, 0.5312, 1.0915, 0.9428],\n",
       "        [0.9643, 0.8189, 0.3995, 0.9779]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat1 + vec1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "198d0e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.7939, 1.0625, 0.8490, 0.6036],\n",
       "        [1.7293, 1.0716, 0.4710, 0.7086],\n",
       "        [1.7939, 1.2247, 0.4995, 0.2182],\n",
       "        [1.7084, 1.3042, 0.6014, 0.2961],\n",
       "        [1.5108, 0.6466, 1.1111, 0.7968]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat2 +vec1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c50837",
   "metadata": {},
   "source": [
    "Since the mat1 and the mat2 dimensions are different, they are not \n",
    "compatible for matrix addition or multiplication. If the dimension remains \n",
    "the same, we can multiply them. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7c39dd",
   "metadata": {},
   "source": [
    "Problem\n",
    "Knowledge of statistical distributions is essential for weight normalization, \n",
    "weight initialization, and computation of gradients in neural network–\n",
    "based operations using PyTorch. How do we know which distributions to \n",
    "use and when to use them?\n",
    "Solution\n",
    "Each statistical distribution follows a pre-established mathematical \n",
    "formula. We are going to use the most commonly used statistical \n",
    "distributions, their arguments in scenarios of problems.\n",
    "How It Works\n",
    "Bernoulli distribution is a special case of binomial distribution, in which \n",
    "the number of trials can be more than one; but in a Bernoulli distribution, \n",
    "the number of experiment or trial remains one. It is a discrete probability \n",
    "distribution of a random variable, which takes a value of 1 when there is \n",
    "probability that an event is a success, and takes a value of 0 when there is \n",
    "probability that an event is a failure. A perfect example of this is tossing a \n",
    "coin, where 1 is heads and 0 is tails. Let’s look at the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13fdf1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
